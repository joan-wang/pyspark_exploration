{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources\n",
    "- LEHD Origin-Destination Employment Statistics (LODES): The definition of variable codes, datasets, etc. can be found at the latest [LODES 7.3 Technical Documentation](https://lehd.ces.census.gov/data/lodes/LODES7/LODESTechDoc7.3.pdf). All LEHD Origin-Destination Employment Statistics (LODES) data are available, as described in the LODES documentation above. No changes have been made to the original CSV files. Data are available from 2002 to 2015. See the documentation above for caveats.\n",
    "- Driving Times and Distances Dataset: Census tracts are 2010 vintage, and the columns are the origin tract, destination travel, travel time in minutes, and travel distance in miles. These data were calculated by the Data Science team at the Urban Institute. See [Github repo](https://github.com/UI-Research/spark-osrm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "warnings.filterwarnings(action='once')\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('pyspark-exploration') \\\n",
    "    .config('spark.driver.cores', '2') \\\n",
    "    .config('spark.executor.memory', '8gb') \\\n",
    "    .config('spark.executor.cores', '2') \\\n",
    "    .getOrCreate()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(df):\n",
    "    \"\"\"\n",
    "    Function to pretty print the toDebugString\n",
    "    \"\"\"\n",
    "    for rddstring in df.rdd.toDebugString().split('\\n'):\n",
    "        print rddstring.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = spark.read.parquet('s3://lsdm-emr-util/lsdm-data/travel-times/drive_times.parquet')\n",
    "od = spark.read.parquet('s3://lsdm-emr-util/lsdm-data/lodes/od/od.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122004331, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(from_tract=u'36103146402', to_tract=u'42091207003', miles=141.2, minutes=184.1),\n",
       " Row(from_tract=u'36103146402', to_tract=u'42091209000', miles=162.7, minutes=203.4)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('from_tract', 'string'),\n",
       " ('to_tract', 'string'),\n",
       " ('miles', 'double'),\n",
       " ('minutes', 'double')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((drive.count(), len(drive.columns)))\n",
    "drive.take(2)\n",
    "drive.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577789908, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(w_geocode=u'271630714002025', h_geocode=u'271630712082020', s000=1, sa01=0, sa02=1, sa03=0, se01=0, se02=1, se03=0, si01=1, si02=0, si03=0, createdate=u'20160219', year=2012),\n",
       " Row(w_geocode=u'271630714002025', h_geocode=u'271630712083004', s000=1, sa01=0, sa02=1, sa03=0, se01=0, se02=1, se03=0, si01=1, si02=0, si03=0, createdate=u'20160219', year=2012)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('w_geocode', 'string'),\n",
       " ('h_geocode', 'string'),\n",
       " ('s000', 'int'),\n",
       " ('sa01', 'int'),\n",
       " ('sa02', 'int'),\n",
       " ('sa03', 'int'),\n",
       " ('se01', 'int'),\n",
       " ('se02', 'int'),\n",
       " ('se03', 'int'),\n",
       " ('si01', 'int'),\n",
       " ('si02', 'int'),\n",
       " ('si03', 'int'),\n",
       " ('createdate', 'string'),\n",
       " ('year', 'int')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((od.count(), len(od.columns)))\n",
    "od.take(2)\n",
    "od.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make census tract and state columns in origin-destination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.withColumn('h_tract', substring(od.h_geocode, 0, 11))\\\n",
    "        .withColumn('w_tract', substring(od.w_geocode, 0, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.withColumn('h_state', substring(od.h_geocode, 0, 2))\\\n",
    "        .withColumn('w_state', substring(od.w_geocode, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(w_geocode=u'271630714002025', h_geocode=u'271630712082020', s000=1, sa01=0, sa02=1, sa03=0, se01=0, se02=1, se03=0, si01=1, si02=0, si03=0, createdate=u'20160219', year=2012, h_tract=u'27163071208', w_tract=u'27163071400', h_state=u'27', w_state=u'27')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make state column in drive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = drive.withColumn('from_state', substring(drive.from_tract, 0, 2))\\\n",
    "            .withColumn('to_state', substring(drive.to_tract, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make \"total\" and \"pct\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_cols = ['sa01', 'sa02', 'sa03']\n",
    "se_cols = ['se01', 'se02', 'se03']\n",
    "si_cols = ['si01', 'si02', 'si03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.withColumn('sa_total', od.sa01+od.sa02+od.sa03)\\\n",
    "    .withColumn('se_total', od.se01+od.se02+od.se03)\\\n",
    "    .withColumn('si_total', od.si01+od.si02+od.si03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_ls, cat_name in [(sa_cols, 'sa_total'), (se_cols, 'se_total'), (si_cols, 'si_total')]:\n",
    "    for col in cat_ls:\n",
    "        new = col + '_pct'\n",
    "        od = od.withColumn(new, od[col]/od[cat_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w_geocode',\n",
       " 'h_geocode',\n",
       " 's000',\n",
       " 'sa01',\n",
       " 'sa02',\n",
       " 'sa03',\n",
       " 'se01',\n",
       " 'se02',\n",
       " 'se03',\n",
       " 'si01',\n",
       " 'si02',\n",
       " 'si03',\n",
       " 'createdate',\n",
       " 'year',\n",
       " 'h_tract',\n",
       " 'w_tract',\n",
       " 'h_state',\n",
       " 'w_state',\n",
       " 'sa_total',\n",
       " 'se_total',\n",
       " 'si_total',\n",
       " 'sa01_pct',\n",
       " 'sa02_pct',\n",
       " 'sa03_pct',\n",
       " 'se01_pct',\n",
       " 'se02_pct',\n",
       " 'se03_pct',\n",
       " 'si01_pct',\n",
       " 'si02_pct',\n",
       " 'si03_pct']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out lineage and partitions of the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137) MapPartitionsRDD[31] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[30] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[29] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   FileScanRDD[28] at javaToPython at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "debug(od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8) MapPartitionsRDD[35] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|  MapPartitionsRDD[34] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|  MapPartitionsRDD[33] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|  FileScanRDD[32] at javaToPython at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "debug(drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od.rdd.getNumPartitions()\n",
    "drive.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join: origin-destination and driving dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repartition od before joining\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.repartition(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try working with just California data first, where origin and destination are state code 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_ca = od.where(\"h_state == 06\" and \"w_state == 06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_ca = drive.where('to_state == 06' and 'from_state == 06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca = od_ca.join(drive_ca, [drive.from_tract == od.h_tract, drive.to_tract == od.w_tract])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca.limit(1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join join with driving, giving us travel times for each origin-destination pair.  \n",
    "Assumption: travel time and distance for a census tract is the same for all its comprising block groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = od.join(drive, [drive.from_tract == od.h_tract, drive.to_tract == od.w_tract])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting dataframe is split across 200 partitions, as we can see from the getNumPartitions method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped aggregation: average proportion of goods-producing jobs per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"year\", df.year.cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = df.groupBy(\"year\").agg(avg(\"si01_pct\"))\n",
    "display(agg_df)\n",
    "agg_df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
