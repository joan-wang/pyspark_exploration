{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources\n",
    "- LEHD Origin-Destination Employment Statistics (LODES): The definition of variable codes, datasets, etc. can be found at the latest [LODES 7.3 Technical Documentation](https://lehd.ces.census.gov/data/lodes/LODES7/LODESTechDoc7.3.pdf). All LEHD Origin-Destination Employment Statistics (LODES) data are available, as described in the LODES documentation above. No changes have been made to the original CSV files. Data are available from 2002 to 2015. See the documentation above for caveats.\n",
    "- Driving Times and Distances Dataset: Census tracts are 2010 vintage, and the columns are the origin tract, destination travel, travel time in minutes, and travel distance in miles. These data were calculated by the Data Science team at the Urban Institute. See [Github repo](https://github.com/UI-Research/spark-osrm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "warnings.filterwarnings(action='once')\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('pyspark-exploration') \\\n",
    "    .config('spark.driver.cores', '2') \\\n",
    "    .config('spark.executor.memory', '8gb') \\\n",
    "    .config('spark.executor.cores', '2') \\\n",
    "    .getOrCreate()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(df):\n",
    "    \"\"\"\n",
    "    Function to pretty print the toDebugString\n",
    "    \"\"\"\n",
    "    for rddstring in df.rdd.toDebugString().split('\\n'):\n",
    "        print rddstring.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = spark.read.parquet('s3://lsdm-emr-util/lsdm-data/travel-times/drive_times.parquet')\n",
    "od = spark.read.parquet('s3://lsdm-emr-util/lsdm-data/lodes/od/od.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122004331, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(from_tract=u'36103146402', to_tract=u'42091207003', miles=141.2, minutes=184.1),\n",
       " Row(from_tract=u'36103146402', to_tract=u'42091209000', miles=162.7, minutes=203.4)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('from_tract', 'string'),\n",
       " ('to_tract', 'string'),\n",
       " ('miles', 'double'),\n",
       " ('minutes', 'double')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((drive.count(), len(drive.columns)))\n",
    "drive.take(2)\n",
    "drive.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577789908, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(w_geocode=u'271630714002025', h_geocode=u'271630712082020', s000=1, sa01=0, sa02=1, sa03=0, se01=0, se02=1, se03=0, si01=1, si02=0, si03=0, createdate=u'20160219', year=2012),\n",
       " Row(w_geocode=u'271630714002025', h_geocode=u'271630712083004', s000=1, sa01=0, sa02=1, sa03=0, se01=0, se02=1, se03=0, si01=1, si02=0, si03=0, createdate=u'20160219', year=2012)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('w_geocode', 'string'),\n",
       " ('h_geocode', 'string'),\n",
       " ('s000', 'int'),\n",
       " ('sa01', 'int'),\n",
       " ('sa02', 'int'),\n",
       " ('sa03', 'int'),\n",
       " ('se01', 'int'),\n",
       " ('se02', 'int'),\n",
       " ('se03', 'int'),\n",
       " ('si01', 'int'),\n",
       " ('si02', 'int'),\n",
       " ('si03', 'int'),\n",
       " ('createdate', 'string'),\n",
       " ('year', 'int')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((od.count(), len(od.columns)))\n",
    "od.take(2)\n",
    "od.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make census tract columns in origin-destination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.withColumn('h_tract', substring(od.h_geocode, 0, 11))\\\n",
    "        .withColumn('w_tract', substring(od.w_geocode, 0, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out lineage and partitions of the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137) MapPartitionsRDD[25] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[24] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   FileScanRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "debug(od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33) MapPartitionsRDD[29] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[28] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[27] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   FileScanRDD[26] at javaToPython at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "debug(drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od.rdd.getNumPartitions()\n",
    "drive.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join origin-destination and driving dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repartition od before joining\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.repartition(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join join with driving, giving us travel times for each origin-destination pair.  \n",
    "Assumption: travel time and distance for a census tract is the same for all its comprising block groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = od.join(drive, [drive.from_tract == od.h_tract, drive.to_tract == od.w_tract])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting dataframe is split across 200 partitions, as we can see from the getNumPartitions method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200) MapPartitionsRDD[45] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[44] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[43] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   ZippedPartitionsRDD2[42] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[36] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   ShuffledRowRDD[35] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "+-(8) MapPartitionsRDD[34] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|  ShuffledRowRDD[33] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "+-(137) MapPartitionsRDD[32] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[31] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   FileScanRDD[30] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[41] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   ShuffledRowRDD[40] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "+-(8) MapPartitionsRDD[39] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|  MapPartitionsRDD[38] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|  FileScanRDD[37] at javaToPython at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "debug(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped aggregation - average travel time by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
