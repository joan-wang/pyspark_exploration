{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources\n",
    "- LEHD Origin-Destination Employment Statistics (LODES): The definition of variable codes, datasets, etc. can be found at the latest [LODES 7.3 Technical Documentation](https://lehd.ces.census.gov/data/lodes/LODES7/LODESTechDoc7.3.pdf). All LEHD Origin-Destination Employment Statistics (LODES) data are available, as described in the LODES documentation above. No changes have been made to the original CSV files. Data are available from 2002 to 2015. See the documentation above for caveats.\n",
    "- Driving Times and Distances Dataset: Census tracts are 2010 vintage, and the columns are the origin tract, destination travel, travel time in minutes, and travel distance in miles. These data were calculated by the Data Science team at the Urban Institute. See [Github repo](https://github.com/UI-Research/spark-osrm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "warnings.filterwarnings(action='once')\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'spark.eventLog.enabled', u'true'),\n",
       " (u'spark.driver.extraLibraryPath',\n",
       "  u'/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native'),\n",
       " (u'spark.blacklist.decommissioning.timeout', u'1h'),\n",
       " (u'spark.yarn.appMasterEnv.SPARK_PUBLIC_DNS', u'$(hostname -f)'),\n",
       " (u'spark.jars.packages', u''),\n",
       " (u'spark.executor.cores', u'4'),\n",
       " (u'spark.driver.host', u'172.31.39.182'),\n",
       " (u'spark.executor.extraJavaOptions',\n",
       "  u\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled -XX:OnOutOfMemoryError='kill -9 %p'\"),\n",
       " (u'spark.eventLog.dir', u'hdfs:///var/log/spark/apps'),\n",
       " (u'spark.sql.hive.metastore.sharedPrefixes',\n",
       "  u'com.amazonaws.services.dynamodbv2'),\n",
       " (u'spark.sql.warehouse.dir', u'hdfs:///user/spark/warehouse'),\n",
       " (u'spark.executor.memory', u'5120M'),\n",
       " (u'spark.app.id', u'application_1519960558342_0001'),\n",
       " (u'spark.serializer.objectStreamReset', u'100'),\n",
       " (u'spark.submit.deployMode', u'client'),\n",
       " (u'spark.history.fs.logDirectory', u'hdfs:///var/log/spark/apps'),\n",
       " (u'spark.ui.filters',\n",
       "  u'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " (u'spark.yarn.historyServer.address',\n",
       "  u'ip-172-31-39-182.us-east-2.compute.internal:18080'),\n",
       " (u'spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  u'ip-172-31-39-182.us-east-2.compute.internal'),\n",
       " (u'spark.history.ui.port', u'18080'),\n",
       " (u'spark.shuffle.service.enabled', u'true'),\n",
       " (u'spark.driver.port', u'45141'),\n",
       " (u'spark.driver.appUIAddress',\n",
       "  u'http://ip-172-31-39-182.us-east-2.compute.internal:4040'),\n",
       " (u'spark.hadoop.yarn.timeline-service.enabled', u'false'),\n",
       " (u'spark.resourceManager.cleanupExpiredHost', u'true'),\n",
       " (u'spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  u'http://ip-172-31-39-182.us-east-2.compute.internal:20888/proxy/application_1519960558342_0001'),\n",
       " (u'spark.driver.extraClassPath',\n",
       "  u'/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar'),\n",
       " (u'spark.executor.id', u'driver'),\n",
       " (u'spark.app.name', u'PySparkShell'),\n",
       " (u'spark.driver.extraJavaOptions',\n",
       "  u\"-XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled -XX:OnOutOfMemoryError='kill -9 %p'\"),\n",
       " (u'spark.master', u'yarn'),\n",
       " (u'spark.decommissioning.timeout.threshold', u'20'),\n",
       " (u'spark.executorEnv.PYTHONPATH',\n",
       "  u'/usr/lib/spark/python/lib/py4j-0.10.4-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.4-src.zip'),\n",
       " (u'spark.sql.catalogImplementation', u'hive'),\n",
       " (u'spark.stage.attempt.ignoreOnDecommissionFetchFailure', u'true'),\n",
       " (u'spark.rdd.compress', u'True'),\n",
       " (u'spark.executor.extraClassPath',\n",
       "  u'/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar'),\n",
       " (u'spark.executor.extraLibraryPath',\n",
       "  u'/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native'),\n",
       " (u'spark.yarn.isPython', u'true'),\n",
       " (u'spark.dynamicAllocation.enabled', u'true'),\n",
       " (u'spark.blacklist.decommissioning.enabled', u'true')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('pyspark-exploration') \\\n",
    "    .config('spark.driver.cores', '4') \\\n",
    "    .config('spark.executor.memory', '16gb') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .getOrCreate()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(df):\n",
    "    \"\"\"\n",
    "    Function to pretty print the toDebugString\n",
    "    \"\"\"\n",
    "    for rddstring in df.rdd.toDebugString().split('\\n'):\n",
    "        print rddstring.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = spark.read.parquet('s3://lsdm-emr-util/lsdm-data/travel-times/drive_times.parquet')\n",
    "od = spark.read.parquet('s3://lsdm-emr-util/lsdm-data/lodes/od/od.parquet')\n",
    "rac = spark.read.parquet('s3://lsdm-emr-util/lsdm-data/lodes/rac/rac.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122004331, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(from_tract=u'36103146402', to_tract=u'42091207003', miles=141.2, minutes=184.1),\n",
       " Row(from_tract=u'36103146402', to_tract=u'42091209000', miles=162.7, minutes=203.4)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('from_tract', 'string'),\n",
       " ('to_tract', 'string'),\n",
       " ('miles', 'double'),\n",
       " ('minutes', 'double')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((drive.count(), len(drive.columns)))\n",
    "drive.take(2)\n",
    "drive.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577789908, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(w_geocode=u'271630714002025', h_geocode=u'271630712082020', s000=1, sa01=0, sa02=1, sa03=0, se01=0, se02=1, se03=0, si01=1, si02=0, si03=0, createdate=u'20160219', year=2012),\n",
       " Row(w_geocode=u'271630714002025', h_geocode=u'271630712083004', s000=1, sa01=0, sa02=1, sa03=0, se01=0, se02=1, se03=0, si01=1, si02=0, si03=0, createdate=u'20160219', year=2012)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('w_geocode', 'string'),\n",
       " ('h_geocode', 'string'),\n",
       " ('s000', 'int'),\n",
       " ('sa01', 'int'),\n",
       " ('sa02', 'int'),\n",
       " ('sa03', 'int'),\n",
       " ('se01', 'int'),\n",
       " ('se02', 'int'),\n",
       " ('se03', 'int'),\n",
       " ('si01', 'int'),\n",
       " ('si02', 'int'),\n",
       " ('si03', 'int'),\n",
       " ('createdate', 'string'),\n",
       " ('year', 'int')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((od.count(), len(od.columns)))\n",
    "od.take(2)\n",
    "od.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80870134, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(h_geocode=u'260010001001000', c000=4, ca01=0, ca02=4, ca03=0, ce01=1, ce02=1, ce03=2, cns01=0, cns02=0, cns03=0, cns04=0, cns05=0, cns06=0, cns07=0, cns08=1, cns09=1, cns10=0, cns11=0, cns12=0, cns13=0, cns14=1, cns15=0, cns16=1, cns17=0, cns18=0, cns19=0, cns20=0, cr01=4, cr02=0, cr03=0, cr04=0, cr05=0, cr07=0, ct01=4, ct02=0, cd01=0, cd02=1, cd03=2, cd04=1, cs01=3, cs02=1, createdate=u'20170919', year=2015),\n",
       " Row(h_geocode=u'260010001001004', c000=2, ca01=0, ca02=2, ca03=0, ce01=1, ce02=1, ce03=0, cns01=0, cns02=0, cns03=0, cns04=0, cns05=0, cns06=0, cns07=0, cns08=0, cns09=0, cns10=1, cns11=0, cns12=0, cns13=0, cns14=0, cns15=0, cns16=0, cns17=0, cns18=1, cns19=0, cns20=0, cr01=2, cr02=0, cr03=0, cr04=0, cr05=0, cr07=0, ct01=2, ct02=0, cd01=1, cd02=1, cd03=0, cd04=0, cs01=1, cs02=1, createdate=u'20170919', year=2015)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('h_geocode', 'string'),\n",
       " ('c000', 'int'),\n",
       " ('ca01', 'int'),\n",
       " ('ca02', 'int'),\n",
       " ('ca03', 'int'),\n",
       " ('ce01', 'int'),\n",
       " ('ce02', 'int'),\n",
       " ('ce03', 'int'),\n",
       " ('cns01', 'int'),\n",
       " ('cns02', 'int'),\n",
       " ('cns03', 'int'),\n",
       " ('cns04', 'int'),\n",
       " ('cns05', 'int'),\n",
       " ('cns06', 'int'),\n",
       " ('cns07', 'int'),\n",
       " ('cns08', 'int'),\n",
       " ('cns09', 'int'),\n",
       " ('cns10', 'int'),\n",
       " ('cns11', 'int'),\n",
       " ('cns12', 'int'),\n",
       " ('cns13', 'int'),\n",
       " ('cns14', 'int'),\n",
       " ('cns15', 'int'),\n",
       " ('cns16', 'int'),\n",
       " ('cns17', 'int'),\n",
       " ('cns18', 'int'),\n",
       " ('cns19', 'int'),\n",
       " ('cns20', 'int'),\n",
       " ('cr01', 'int'),\n",
       " ('cr02', 'int'),\n",
       " ('cr03', 'int'),\n",
       " ('cr04', 'int'),\n",
       " ('cr05', 'int'),\n",
       " ('cr07', 'int'),\n",
       " ('ct01', 'int'),\n",
       " ('ct02', 'int'),\n",
       " ('cd01', 'int'),\n",
       " ('cd02', 'int'),\n",
       " ('cd03', 'int'),\n",
       " ('cd04', 'int'),\n",
       " ('cs01', 'int'),\n",
       " ('cs02', 'int'),\n",
       " ('createdate', 'string'),\n",
       " ('year', 'int')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((rac.count(), len(rac.columns)))\n",
    "rac.take(2)\n",
    "rac.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make census tract and state columns in origin-destination and residential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.withColumn('h_tract', substring(od.h_geocode, 0, 11))\\\n",
    "        .withColumn('w_tract', substring(od.w_geocode, 0, 11))\\\n",
    "        .withColumn('h_state', substring(od.h_geocode, 0, 2))\\\n",
    "        .withColumn('w_state', substring(od.w_geocode, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rac = rac.withColumn('h_tract', substring(rac.h_geocode, 0, 11))\\\n",
    "        .withColumn('h_state', substring(rac.h_geocode, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make state column in drive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = drive.withColumn('from_state', substring(drive.from_tract, 0, 2))\\\n",
    "            .withColumn('to_state', substring(drive.to_tract, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make \"total\" and \"pct\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_cols = ['sa01', 'sa02', 'sa03']\n",
    "se_cols = ['se01', 'se02', 'se03']\n",
    "si_cols = ['si01', 'si02', 'si03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.withColumn('sa_total', od.sa01+od.sa02+od.sa03)\\\n",
    "    .withColumn('se_total', od.se01+od.se02+od.se03)\\\n",
    "    .withColumn('si_total', od.si01+od.si02+od.si03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_ls, cat_name in [(sa_cols, 'sa_total'), (se_cols, 'se_total'), (si_cols, 'si_total')]:\n",
    "    for col in cat_ls:\n",
    "        new = col + '_pct'\n",
    "        od = od.withColumn(new, od[col]/od[cat_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out lineage and partitions of the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137) MapPartitionsRDD[102] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[101] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[100] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   FileScanRDD[99] at javaToPython at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "debug(od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17) MapPartitionsRDD[106] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[105] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[104] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   FileScanRDD[103] at javaToPython at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "debug(drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od.rdd.getNumPartitions()\n",
    "drive.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join: origin-destination and driving dataframes  \n",
    "Assumption: travel time and distance for a census tract is the same for all its comprising block groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repartition od before joining\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.repartition(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try working with just California data first, where origin and destination are state code 06  \n",
    "Join od_ca and drive_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_ca = od.where(\"h_state == 06\" and \"w_state == 06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_ca = drive.where('to_state == 06' and 'from_state == 06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca = od_ca.join(drive_ca, [drive.from_tract == od.h_tract, drive.to_tract == od.w_tract])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(w_geocode=u'060014355002011', h_geocode=u'060014001001045', s000=1, sa01=1, sa02=0, sa03=0, se01=0, se02=1, se03=0, si01=0, si02=0, si03=1, createdate=u'20160228', year=2008, h_tract=u'06001400100', w_tract=u'06001435500', h_state=u'06', w_state=u'06', sa_total=1, se_total=1, si_total=1, sa01_pct=1.0, sa02_pct=0.0, sa03_pct=0.0, se01_pct=0.0, se02_pct=1.0, se03_pct=0.0, si01_pct=0.0, si02_pct=0.0, si03_pct=1.0, from_tract=u'06001400100', to_tract=u'06001435500', miles=16.9, minutes=24.2, from_state=u'06', to_state=u'06')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca.limit(1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now join full od with driving, giving us travel times for each origin-destination pair.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = od.join(drive, [drive.from_tract == od.h_tract, drive.to_tract == od.w_tract])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting dataframe is split across 200 partitions, as we can see from the getNumPartitions method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200) MapPartitionsRDD[137] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[136] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[135] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   ZippedPartitionsRDD2[134] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[128] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   ShuffledRowRDD[127] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "+-(17) MapPartitionsRDD[126] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   ShuffledRowRDD[125] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "+-(137) MapPartitionsRDD[124] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[123] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   FileScanRDD[122] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[133] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   ShuffledRowRDD[132] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "+-(65) MapPartitionsRDD[131] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   MapPartitionsRDD[130] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "|   FileScanRDD[129] at javaToPython at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "debug(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped aggregation: proportion of goods-producing jobs per year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, start with California only  \n",
    "\n",
    "The proportion of jobs in California in Goods Producing industry sectors (\"si01\") has steadily declined over the past decade as the economy moved away from manufacturing and towards services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ca = df_ca.groupBy(\"year\").agg(sum(\"si01\"), sum('si02'), sum('si03'))\n",
    "results_ca = agg_ca.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ca_df = pd.DataFrame(results_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ca_df.columns = ['year', 'si01', 'si02', 'si03']\n",
    "agg_ca_df['total_jobs'] = agg_ca_df.si01 + agg_ca_df.si02 + agg_ca_df.si03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ca_df['pct_si01'] = agg_ca_df.si01 / agg_ca_df.total_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>si01</th>\n",
       "      <th>si02</th>\n",
       "      <th>si03</th>\n",
       "      <th>total_jobs</th>\n",
       "      <th>pct_si01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2002</td>\n",
       "      <td>1061707</td>\n",
       "      <td>1033147</td>\n",
       "      <td>3245012</td>\n",
       "      <td>5339866</td>\n",
       "      <td>0.198827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>1019401</td>\n",
       "      <td>1024673</td>\n",
       "      <td>3263365</td>\n",
       "      <td>5307439</td>\n",
       "      <td>0.192070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004</td>\n",
       "      <td>1028667</td>\n",
       "      <td>1022742</td>\n",
       "      <td>3306224</td>\n",
       "      <td>5357633</td>\n",
       "      <td>0.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2005</td>\n",
       "      <td>1052749</td>\n",
       "      <td>1053289</td>\n",
       "      <td>3372850</td>\n",
       "      <td>5478888</td>\n",
       "      <td>0.192146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>1045599</td>\n",
       "      <td>1071275</td>\n",
       "      <td>3441228</td>\n",
       "      <td>5558102</td>\n",
       "      <td>0.188122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>1025099</td>\n",
       "      <td>1065219</td>\n",
       "      <td>3474935</td>\n",
       "      <td>5565253</td>\n",
       "      <td>0.184196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008</td>\n",
       "      <td>967440</td>\n",
       "      <td>1052308</td>\n",
       "      <td>3553468</td>\n",
       "      <td>5573216</td>\n",
       "      <td>0.173587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>877083</td>\n",
       "      <td>977576</td>\n",
       "      <td>3534286</td>\n",
       "      <td>5388945</td>\n",
       "      <td>0.162756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010</td>\n",
       "      <td>823689</td>\n",
       "      <td>978019</td>\n",
       "      <td>3610732</td>\n",
       "      <td>5412440</td>\n",
       "      <td>0.152184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011</td>\n",
       "      <td>827560</td>\n",
       "      <td>1009758</td>\n",
       "      <td>3651098</td>\n",
       "      <td>5488416</td>\n",
       "      <td>0.150783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>824822</td>\n",
       "      <td>1018812</td>\n",
       "      <td>3702850</td>\n",
       "      <td>5546484</td>\n",
       "      <td>0.148711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>847619</td>\n",
       "      <td>1048702</td>\n",
       "      <td>3813783</td>\n",
       "      <td>5710104</td>\n",
       "      <td>0.148442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014</td>\n",
       "      <td>891843</td>\n",
       "      <td>1067155</td>\n",
       "      <td>3908049</td>\n",
       "      <td>5867047</td>\n",
       "      <td>0.152009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>939611</td>\n",
       "      <td>1108226</td>\n",
       "      <td>4070729</td>\n",
       "      <td>6118566</td>\n",
       "      <td>0.153567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year     si01     si02     si03  total_jobs  pct_si01\n",
       "13  2002  1061707  1033147  3245012     5339866  0.198827\n",
       "0   2003  1019401  1024673  3263365     5307439  0.192070\n",
       "6   2004  1028667  1022742  3306224     5357633  0.192000\n",
       "9   2005  1052749  1053289  3372850     5478888  0.192146\n",
       "3   2006  1045599  1071275  3441228     5558102  0.188122\n",
       "1   2007  1025099  1065219  3474935     5565253  0.184196\n",
       "12  2008   967440  1052308  3553468     5573216  0.173587\n",
       "8   2009   877083   977576  3534286     5388945  0.162756\n",
       "10  2010   823689   978019  3610732     5412440  0.152184\n",
       "11  2011   827560  1009758  3651098     5488416  0.150783\n",
       "7   2012   824822  1018812  3702850     5546484  0.148711\n",
       "4   2013   847619  1048702  3813783     5710104  0.148442\n",
       "5   2014   891843  1067155  3908049     5867047  0.152009\n",
       "2   2015   939611  1108226  4070729     6118566  0.153567"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_ca_df.sort_values('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do it for the whole country. We see a similar pattern of declining percentage of Goods Producing jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_full = df.groupBy(\"year\").agg(sum(\"si01\"), sum('si02'), sum('si03'))\n",
    "results_full = agg_full.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agg_full_df = pd.DataFrame(results_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_full_df.columns = ['year', 'si01', 'si02', 'si03']\n",
    "agg_full_df['total_jobs'] = agg_full_df.si01 + agg_full_df.si02 + agg_full_df.si03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_full_df['pct_si01'] = agg_full_df.si01 / agg_full_df.total_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>si01</th>\n",
       "      <th>si02</th>\n",
       "      <th>si03</th>\n",
       "      <th>total_jobs</th>\n",
       "      <th>pct_si01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2002</td>\n",
       "      <td>9049198</td>\n",
       "      <td>9483453</td>\n",
       "      <td>27533384</td>\n",
       "      <td>46066035</td>\n",
       "      <td>0.196440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>8865886</td>\n",
       "      <td>9600409</td>\n",
       "      <td>27942515</td>\n",
       "      <td>46408810</td>\n",
       "      <td>0.191039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004</td>\n",
       "      <td>9121645</td>\n",
       "      <td>9926406</td>\n",
       "      <td>29220115</td>\n",
       "      <td>48268166</td>\n",
       "      <td>0.188978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2005</td>\n",
       "      <td>9300469</td>\n",
       "      <td>10086742</td>\n",
       "      <td>29813064</td>\n",
       "      <td>49200275</td>\n",
       "      <td>0.189033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>9447083</td>\n",
       "      <td>10167374</td>\n",
       "      <td>30462147</td>\n",
       "      <td>50076604</td>\n",
       "      <td>0.188653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>9357236</td>\n",
       "      <td>10167600</td>\n",
       "      <td>30749160</td>\n",
       "      <td>50273996</td>\n",
       "      <td>0.186125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008</td>\n",
       "      <td>9023304</td>\n",
       "      <td>10151678</td>\n",
       "      <td>31044813</td>\n",
       "      <td>50219795</td>\n",
       "      <td>0.179676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>7960944</td>\n",
       "      <td>9624079</td>\n",
       "      <td>30834938</td>\n",
       "      <td>48419961</td>\n",
       "      <td>0.164415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010</td>\n",
       "      <td>7515555</td>\n",
       "      <td>9468287</td>\n",
       "      <td>31314073</td>\n",
       "      <td>48297915</td>\n",
       "      <td>0.155608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011</td>\n",
       "      <td>7827414</td>\n",
       "      <td>9978429</td>\n",
       "      <td>32872199</td>\n",
       "      <td>50678042</td>\n",
       "      <td>0.154454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>7968824</td>\n",
       "      <td>10138958</td>\n",
       "      <td>33284584</td>\n",
       "      <td>51392366</td>\n",
       "      <td>0.155059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>8055568</td>\n",
       "      <td>10244986</td>\n",
       "      <td>33826994</td>\n",
       "      <td>52127548</td>\n",
       "      <td>0.154536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014</td>\n",
       "      <td>8356186</td>\n",
       "      <td>10390904</td>\n",
       "      <td>34407571</td>\n",
       "      <td>53154661</td>\n",
       "      <td>0.157205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>8599917</td>\n",
       "      <td>10707646</td>\n",
       "      <td>35311446</td>\n",
       "      <td>54619009</td>\n",
       "      <td>0.157453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year     si01      si02      si03  total_jobs  pct_si01\n",
       "13  2002  9049198   9483453  27533384    46066035  0.196440\n",
       "0   2003  8865886   9600409  27942515    46408810  0.191039\n",
       "6   2004  9121645   9926406  29220115    48268166  0.188978\n",
       "9   2005  9300469  10086742  29813064    49200275  0.189033\n",
       "3   2006  9447083  10167374  30462147    50076604  0.188653\n",
       "1   2007  9357236  10167600  30749160    50273996  0.186125\n",
       "12  2008  9023304  10151678  31044813    50219795  0.179676\n",
       "8   2009  7960944   9624079  30834938    48419961  0.164415\n",
       "10  2010  7515555   9468287  31314073    48297915  0.155608\n",
       "11  2011  7827414   9978429  32872199    50678042  0.154454\n",
       "7   2012  7968824  10138958  33284584    51392366  0.155059\n",
       "4   2013  8055568  10244986  33826994    52127548  0.154536\n",
       "5   2014  8356186  10390904  34407571    53154661  0.157205\n",
       "2   2015  8599917  10707646  35311446    54619009  0.157453"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_full_df.sort_values('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window function: calculate central moving average number jobs at census tract level (RAC)\n",
    "\n",
    "Central moving average calculates the average between previous year, current year, and next year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by tract level to get larger number of jobs to work with\n",
    "rac_tract = rac.groupBy(\"h_tract\", \"year\").agg(sum(\"c000\").alias('c000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(h_tract=u'48027020701', year=2007, c000=587)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rac_tract.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(\"h_tract\")\\\n",
    "            .orderBy(\"year\")\\\n",
    "            .rowsBetween(Window.currentRow -1, Window.currentRow + 1)\n",
    "avg_jobs = avg('c000').over(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rac_tract_avg = rac_tract.select('year', 'h_tract', avg_jobs.alias(\"central_avg_jobs\"))\\\n",
    "                    .orderBy('h_tract', 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----------------+\n",
      "|year|    h_tract| central_avg_jobs|\n",
      "+----+-----------+-----------------+\n",
      "|2002|01001020100|            812.0|\n",
      "|2003|01001020100|            803.0|\n",
      "|2004|01001020100|796.3333333333334|\n",
      "|2005|01001020100|825.3333333333334|\n",
      "|2006|01001020100|865.6666666666666|\n",
      "|2007|01001020100|913.3333333333334|\n",
      "|2008|01001020100|            910.0|\n",
      "|2009|01001020100|877.3333333333334|\n",
      "|2010|01001020100|822.6666666666666|\n",
      "|2011|01001020100|            768.0|\n",
      "+----+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rac_tract_avg.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape RAC data from long to wide based on year column\n",
    "\n",
    "Result is total number of jobs for each residence area by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_rac_tract = rac_tract.groupby('h_tract')\\\n",
    "    .pivot(\"year\")\\\n",
    "    .sum(\"c000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|    h_tract|2002|2003|2004|2005|2006|2007|2008|2009|2010|2011|2012|2013|2014|2015|\n",
      "+-----------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|27145010402|1455|1504|1589|1636|1685|1752|1949|1902|1924|2056|2278|2139|2185|2124|\n",
      "|09007595101|1684|1655|1411|1756|1677|1592|1780|1562|1735|1988|1909|1954|1910|1852|\n",
      "|06077004204|1341|1415|1412|1476|1087|1496|1389|1341|1359|1043|1109|1205|1373|1304|\n",
      "|48167723800|1731|1902|1844|1977|1888|1783|1844|1790|1715|2234|2244|2264|1675|1802|\n",
      "|36055007801|1474|1308|1277|1273|1204|1138|1224|1172|1182|1083|1146| 987|1090|1229|\n",
      "+-----------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted_rac_tract.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: How do age and earnings affect distance and time traveled for work in California?\n",
    "\n",
    "Regression equation 1:  \n",
    "dist = b0 + b1&ast;sa02_pct + b2&ast;sa03_pct + b3&ast;se02_pct + b4&ast;se03_pct + error  \n",
    "\n",
    "Regression equation 2:  \n",
    "minutes = b0 + b1&ast;sa02_pct + b2&ast;sa03_pct + b3&ast;se02_pct + b4&ast;se03_pct + error  \n",
    "\n",
    "sa02 = % of jobs for workers age 30 to 54  \n",
    "sa03 = % of jobs for workers age 55 or older  \n",
    "se02 = % of jobs with earnings 1251/month to 3333/month  \n",
    "se03 = % of jobs with earnings greater than 3333/month  \n",
    "\n",
    "Note: \n",
    "- First category of each group (age an earnings) are left out of equation to serve as baseline\n",
    "- Filtering data to 2015 so that each origin/destination pair only counts as one observation\n",
    "\n",
    "This regression explores the relationship between job composition and travel distance by census block. By regressing travel distance on these four variables, we can evaluate whether age and earnings of jobs in a origin/destination pair has an effect on the travel distance. The results show that there's very little relationship.\n",
    "\n",
    "R-squared is very low, meaning that very little of the variance in outcome can be explained by regressors.  \n",
    "RMSE is the standard deviation of the unexplained variance and is in the same units as the outcome variable. It is very high and exceeds the intercept in both regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with regression equation 1, for travel distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca_15 = df_ca.where('year == 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca_reg = df_ca_15[['sa02_pct', 'sa03_pct', 'se02_pct', 'se03_pct', 'miles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[0.0,0.0,1.0,0.0]| 16.9|\n",
      "|[1.0,0.0,0.0,1.0]| 45.3|\n",
      "|[0.0,1.0,0.0,1.0]| 16.3|\n",
      "|[1.0,0.0,1.0,0.0]| 16.3|\n",
      "|[0.0,0.0,0.0,0.0]| 16.1|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ca_reg_vect = df_ca_reg.rdd.map(lambda x: [Vectors.dense(x[0:4]), x[-1]]).toDF(['features', 'label'])\n",
    "df_ca_reg_vect.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(df_ca_reg_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = lr_model.transform(df_ca_reg_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-3.04770349959,-4.00597846361,1.01359120305,1.67570408979]\n",
      "Intercept: 27.386367196\n"
     ]
    }
   ],
   "source": [
    "# print the coefficients and intercept \n",
    "print(\"Coefficients: %s\" % str(lr_model.coefficients))\n",
    "print(\"Intercept: %s\" % str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 35.0205139273\n",
      "r2: 0.00161860037597\n"
     ]
    }
   ],
   "source": [
    "# evaluate results\n",
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: {}\".format(trainingSummary.rootMeanSquaredError))\n",
    "print(\"r2: {}\".format(trainingSummary.r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try regression equation 2, time traveled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca_reg = df_ca_15[['sa02_pct', 'sa03_pct', 'se02_pct', 'se03_pct', 'minutes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[0.0,0.0,1.0,0.0]| 24.2|\n",
      "|[1.0,0.0,0.0,1.0]| 60.8|\n",
      "|[1.0,0.0,1.0,0.0]| 22.2|\n",
      "|[0.0,1.0,0.0,1.0]| 22.2|\n",
      "|[0.0,0.0,0.0,0.0]| 24.9|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ca_reg_vect = df_ca_reg.rdd.map(lambda x: [Vectors.dense(x[0:4]), x[-1]]).toDF(['features', 'label'])\n",
    "df_ca_reg_vect.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(df_ca_reg_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = lr_model.transform(df_ca_reg_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-3.71211382637,-4.69138754015,1.49404738438,2.66253720749]\n",
      "Intercept: 37.6802550132\n"
     ]
    }
   ],
   "source": [
    "# print the coefficients and intercept \n",
    "print(\"Coefficients: %s\" % str(lr_model.coefficients))\n",
    "print(\"Intercept: %s\" % str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 43.3768570689\n",
      "r2: 0.00162553820719\n"
     ]
    }
   ],
   "source": [
    "# evaluate results\n",
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: {}\".format(trainingSummary.rootMeanSquaredError))\n",
    "print(\"r2: {}\".format(trainingSummary.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
